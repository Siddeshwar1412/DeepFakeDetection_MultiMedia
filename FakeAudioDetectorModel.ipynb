{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip numpy pandas librosa tensorflow keras scikit-learn matplotlib seaborn soundfile audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "# Paths\n",
    "DATASET_PATHS = {\n",
    "    \"train\": r\"E:\\Minor_project\\FakeAudioDetector\\DataSet\\training\",\n",
    "    \"val\": r\"E:\\Minor_project\\FakeAudioDetector\\DataSet\\validation\",\n",
    "    \"test\": r\"E:\\Minor_project\\FakeAudioDetector\\DataSet\\testing\"\n",
    "}\n",
    "MODEL_PATH = r\"E:\\Minor_project\\FakeAudioDetector\\fake_audio_model.h5\"\n",
    "NEW_AUDIO_PATH = r\"E:\\Minor_project\\FakeAudioDetector\\AudioFile\\file16.mp3_16k.mp3_norm.mp3_mono.mp3_silence.mp3_2sec.mp3\"\n",
    "\n",
    "# Extract Features (Optimized: Memory-efficient processing)\n",
    "def extract_features(file_path, max_pad_len=174):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=22050, mono=True, duration=2.0)  # Loads only 2 seconds to reduce RAM usage\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, max(0, max_pad_len - mfccs.shape[1]))), mode='constant')[:, :max_pad_len]\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load Dataset (Optimized: Avoids redundant loading)\n",
    "def load_dataset(folder_path):\n",
    "    X, Y = [], []\n",
    "    label_map = {label: idx for idx, label in enumerate(os.listdir(folder_path))}\n",
    "    \n",
    "    for label, idx in label_map.items():\n",
    "        subfolder = os.path.join(folder_path, label)\n",
    "        for file in os.listdir(subfolder):\n",
    "            file_path = os.path.join(subfolder, file)\n",
    "            if file.endswith(('.wav', '.mp3')):\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    X.append(features)\n",
    "                    Y.append(idx)\n",
    "\n",
    "    return np.array(X), to_categorical(np.array(Y), len(label_map))\n",
    "\n",
    "# Load Data Efficiently\n",
    "X_train, Y_train = load_dataset(DATASET_PATHS[\"train\"])\n",
    "X_val, Y_val = load_dataset(DATASET_PATHS[\"val\"])\n",
    "X_test, Y_test = load_dataset(DATASET_PATHS[\"test\"])\n",
    "\n",
    "# Reshape for CNN\n",
    "X_train = X_train.reshape(-1, 40, 174, 1)\n",
    "X_val = X_val.reshape(-1, 40, 174, 1)\n",
    "X_test = X_test.reshape(-1, 40, 174, 1)\n",
    "\n",
    "# Build Optimized CNN Model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(40, 174, 1)),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load or Train Model\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"Loaded saved model.\")\n",
    "else:\n",
    "    model = build_model()\n",
    "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=15, batch_size=16, verbose=2)\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"Model trained and saved.\")\n",
    "\n",
    "# Evaluate Model Performance\n",
    "def evaluate_model():\n",
    "    Y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Classification Report:\\n\", classification_report(Y_test.argmax(axis=1), Y_pred.argmax(axis=1)))\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=[\"Fake\", \"Real\"], yticklabels=[\"Fake\", \"Real\"])\n",
    "    plt.title('Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Predict Fake or Real for a New Audio File\n",
    "def predict_audio(audio_path):\n",
    "    features = extract_features(audio_path)\n",
    "    if features is not None:\n",
    "        features = features.reshape(1, 40, 174, 1)\n",
    "        prediction = model.predict(features)\n",
    "        print(f\"Prediction: {'Real' if np.argmax(prediction) == 1 else 'Fake'}\")\n",
    "\n",
    "# Run Prediction & Evaluation\n",
    "predict_audio(NEW_AUDIO_PATH)\n",
    "evaluate_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
